"""
agent.py

ë©”ì¸ LangGraph ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ì •ì˜
ê°•ì˜ ì½”ë“œ ì°¸ì¡°:
- example.py: StateGraph êµ¬ì„±, conditional_edges
- final_ai_project/app/agent.py: AIAgent í´ë˜ìŠ¤ íŒ¨í„´
- human_in_the_loop/app/agent.py: checkpointer, interrupt ì§€ì›
"""

from langgraph.graph import StateGraph, END
from typing import Dict, Any, List

from ..schemas import AgentState
from ..memory.short_term import ShortTermMemory
from .nodes import llm_node, tool_node, route_after_llm, reflection_node


class MovieChatAgent:
    """
    ì˜í™” ì¶”ì²œ ì±„íŒ… ì—ì´ì „íŠ¸

    ê°•ì˜ ì½”ë“œ íŒ¨í„´ í†µí•©:
    - final_ai_project/app/agent.pyì˜ AIAgent í´ë˜ìŠ¤ êµ¬ì¡°
    - example.pyì˜ ê·¸ë˜í”„ êµ¬ì„± ë°©ì‹
    - human_in_the_loop/app/agent.pyì˜ checkpointer í™œìš©
    """

    def __init__(self, enable_memory: bool = True):
        """
        ì—ì´ì „íŠ¸ ì´ˆê¸°í™”

        Args:
            enable_memory: ëŒ€í™” ë©”ëª¨ë¦¬ í™œì„±í™” ì—¬ë¶€ (checkpointer ì‚¬ìš©)
        """
        # Short Term Memory ì´ˆê¸°í™”
        print(f"[MovieChatAgent] ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        self.short_term_memory = ShortTermMemory(enable=enable_memory)
        self.checkpointer = self.short_term_memory.get_checkpointer()
        print(f"[MovieChatAgent] Short Term Memory: {'í™œì„±í™”' if enable_memory else 'ë¹„í™œì„±í™”'}")
        self.graph = self._build_graph()
        print(f"[MovieChatAgent] ê·¸ë˜í”„ ë¹Œë“œ ì™„ë£Œ")

    def _build_graph(self):
        """
        LangGraph êµ¬ì„±

        ì°¸ê³ :
        - example.pyì˜ ê·¸ë˜í”„ êµ¬ì„± (lines 99-114)
        - final_ai_project/app/agent.pyì˜ workflow êµ¬ì„± (lines 30-35)
        """
        # StateGraph ìƒì„±
        builder = StateGraph(AgentState)

        # ë…¸ë“œ ì¶”ê°€
        builder.add_node("llm", llm_node)
        builder.add_node("tool", tool_node)
        builder.add_node("reflection", reflection_node)  # Reflection ë…¸ë“œ ì¶”ê°€

        # ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸ ì„¤ì •
        builder.set_entry_point("llm")

        # Conditional Edge: LLM â†’ Tool or Reflection or END
        builder.add_conditional_edges(
            "llm",
            route_after_llm,
            {
                "tool": "tool",
                "reflection": "reflection",
                "END": END
            }
        )

        # Tool â†’ LLM (ReAct loop)
        builder.add_edge("tool", "llm")
        
        # Reflection â†’ END (ë©”ëª¨ë¦¬ ì €ì¥ í›„ ì¢…ë£Œ)
        builder.add_edge("reflection", END)

        # ì»´íŒŒì¼
        return builder.compile(checkpointer=self.checkpointer)

    def invoke(self, input_data: Dict[str, Any], config: Dict[str, Any] = None):
        """
        ê·¸ë˜í”„ ì‹¤í–‰

        ì°¸ê³ :
        - final_ai_project/app/agent.pyì˜ invoke (line 91)
        - human_in_the_loop/app/agent.pyì˜ invoke (line 70)
        """
        return self.graph.invoke(input_data, config=config)

    def stream(self, input_data: Dict[str, Any], config: Dict[str, Any] = None):
        """
        ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰

        ì°¸ê³ : examples/2_stream.py
        """
        return self.graph.stream(input_data, config=config)

    def get_response(self, user_message: str, history: List[List[str]] = None) -> str:
        """
        Gradio UIë¥¼ ìœ„í•œ ì¸í„°í˜ì´ìŠ¤

        ì°¸ê³ : final_ai_project/app/agent.pyì˜ get_response (lines 74-96)
        """
        if history is None:
            history = []

        # ì‹œìŠ¤í…œ ë©”ì‹œì§€
        conversation = [
            {
                "role": "system",
                "content": (
                    "ë‹¹ì‹ ì€ ì˜í™” ì •ë³´/RAG ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n"
                    "- ì˜í™” ì •ë³´/ì œëª©/ì¤„ê±°ë¦¬/ë°°ìš°/ê°ë…/í‰ì  ì§ˆë¬¸ì€ ë°˜ë“œì‹œ search_ragë¡œ ê·¼ê±°ë¥¼ ì°¾ì€ ë’¤ ë‹µí•©ë‹ˆë‹¤.\n"
                    "- ì¥ë¥´/ì¶”ì²œ ìš”ì²­(ì˜ˆ: ê³µí¬ ì˜í™” ì¶”ì²œ)ì€ recommend_by_genreë¥¼ í˜¸ì¶œí•´ ì¥ë¥´ í•„í„° + í‰ì /ì¸ê¸°ìˆœìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.\n"
                    "  â€¢ ì‚¬ìš©ìê°€ 'ë‹¤ë¥¸ ì˜í™” ì¶”ì²œ' ë˜ëŠ” 'ì œì™¸í•˜ê³ 'ë¼ê³  í•˜ë©´, ì´ì „ ëŒ€í™”ì—ì„œ ì¶”ì²œí•œ ì˜í™” ì œëª©ì„ exclude_titles íŒŒë¼ë¯¸í„°ì— ì „ë‹¬í•˜ì„¸ìš”.\n"
                    "  â€¢ ì˜ˆ: recommend_by_genre(query='SF', exclude_titles='2001: A Space Odyssey, Finch')\n"
                    "- ë„êµ¬ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìœ¼ë©´ 'ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤'ë¼ê³  ì†”ì§íˆ ë‹µí•©ë‹ˆë‹¤.\n"
                    "- ì˜ë¯¸ ì—†ëŠ” ì…ë ¥(adfadf ë“±)ì´ë©´ ì—­í• ì„ ë§í•˜ê³  ë‹¤ì‹œ ì§ˆë¬¸ì„ ìœ ë„í•©ë‹ˆë‹¤.\n"
                    "- ë‹µë³€ í˜•ì‹: ê°„ê²°í•œ í•œêµ­ì–´, bullet 3~5ê°œ ì´ë‚´.\n"
                    "- ğŸ–¼ï¸ í¬ìŠ¤í„° URL(ìˆì„ ë•Œ)\n"
                    "- ğŸ¬ ì‘í’ˆ ì œëª©\n"
                    "- ğŸ“… ê°œë´‰ì¼\n"
                    "- ğŸ­ ì¥ë¥´ / í‚¤ì›Œë“œ\n"
                    "- â­ í‰ì \n"
                    "- ğŸ“– ì¤„ê±°ë¦¬\n"
                    "- ì¶”ì¸¡ ê¸ˆì§€, ë°˜ë“œì‹œ ë„êµ¬ ê²°ê³¼ì— ê¸°ë°˜í•´ ë‹µí•˜ì‹­ì‹œì˜¤."
                )
            }
        ]


        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€
        for item in history or []:
            if isinstance(item, (list, tuple)) and len(item) >= 2:
                user_msg, bot_msg = item[:2]
            elif isinstance(item, dict):
                if item.get("role") == "user":
                    user_msg, bot_msg = item.get("content"), None
                elif item.get("role") == "assistant":
                    user_msg, bot_msg = None, item.get("content")
                else:
                    continue
            else:
                continue

            if user_msg:
                conversation.append({"role": "user", "content": str(user_msg)})
            if bot_msg:
                conversation.append({"role": "assistant", "content": str(bot_msg)})


        # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
        conversation.append({"role": "user", "content": str(user_message)})

        # ê·¸ë˜í”„ ì‹¤í–‰ ì…ë ¥
        inputs = {
            "messages": conversation,
            "user_query": user_message,
            "tool_result": None,
            "retrieved_contexts": [],
            "final_answer": None,
            "relevant_memories": [],  # ë©”ëª¨ë¦¬ í•„ë“œ ì´ˆê¸°í™”
            "saved_memory_id": None
        }

        # checkpointer(MemorySaver)ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” thread_id ë“± configurable í‚¤ê°€ í•„ìš”í•¨
        # Gradio ChatInterfaceì—ì„œëŠ” ì„¸ì…˜ ë‹¨ìœ„ ìŠ¤ë ˆë“œë¡œ ê°„ë‹¨íˆ ê³ ì • IDë¥¼ ì‚¬ìš©
        config = {
            "configurable": {
                "thread_id": "gradio-chat-session"
            }
        }

        result_state = self.graph.invoke(inputs, config=config)

        # ìµœì¢… ë‹µë³€ ì¶”ì¶œ
        if result_state.get("final_answer"):
            answer = result_state["final_answer"]
            print(f"[get_response] final answer preview: \n {answer}")
            return result_state["final_answer"]

        # messagesì—ì„œ ë§ˆì§€ë§‰ assistant ë©”ì‹œì§€ ì¶”ì¶œ
        messages = result_state.get("messages", [])
        for msg in reversed(messages):
            if isinstance(msg, dict) and msg.get("role") == "assistant":
                return msg.get("content", "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


# ==========================================
# ì§ì ‘ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
# ==========================================
if __name__ == "__main__":
    print("=== MovieChatAgent í…ŒìŠ¤íŠ¸ ===\n")

    agent = MovieChatAgent(enable_memory=False)

    # í…ŒìŠ¤íŠ¸ 1: ê°„ë‹¨í•œ ì§ˆë¬¸
    print("Q1: ì•ˆë…•í•˜ì„¸ìš”!")
    response1 = agent.get_response("ì•ˆë…•í•˜ì„¸ìš”!", [])
    print(f"A1: {response1}\n")

    # í…ŒìŠ¤íŠ¸ 2: ì˜í™” ê²€ìƒ‰
    print("Q2: ì¸í„°ìŠ¤í…”ë¼ì— ëŒ€í•´ ì•Œë ¤ì¤˜")
    response2 = agent.get_response("ì¸í„°ìŠ¤í…”ë¼ì— ëŒ€í•´ ì•Œë ¤ì¤˜", [])
    print(f"A2: {response2}\n")

    # í…ŒìŠ¤íŠ¸ 3: ì˜í™” ì¶”ì²œ
    print("Q3: SF ì˜í™” ì¶”ì²œí•´ì¤˜")
    response3 = agent.get_response("SF ì˜í™” ì¶”ì²œí•´ì¤˜", [])
    print(f"A3: {response3}\n")

    print("=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
