"""
vectorstore.py

ChromaDB ê¸°ë°˜ ë²¡í„° ì €ì¥ì†Œ (ê³¼ì œ ë°©ì‹)
ì°¸ê³ :
- ê³¼ì œ ì½”ë“œì˜ build_index í•¨ìˆ˜
- utils.pyì˜ embed_texts (lines 63-65)
"""

import os
from typing import List, Dict, Any
import chromadb
from chromadb.config import Settings
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()


class MovieVectorStore:
    """
    ChromaDB ê¸°ë°˜ ì˜í™” ì •ë³´ ë²¡í„° ì €ì¥ì†Œ (ê³¼ì œ ë°©ì‹)

    ê³¼ì œ ë°©ì‹:
    - OpenAIë¡œ ì§ì ‘ embedding ìƒì„±
    - ChromaDBì— embeddingê³¼ í•¨ê»˜ ì €ì¥
    """

    def __init__(self, persist_directory: str = "data/vector_db", collection_name: str = "movies"):
        """
        ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”

        Args:
            persist_directory: ChromaDB ì €ì¥ ê²½ë¡œ
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
        """
        self.persist_directory = persist_directory
        self.collection_name = collection_name

        # OpenAI client
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.embed_model = os.getenv("EMBED_MODEL", "text-embedding-3-small")

        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ìë™ persist)
        self.client = chromadb.PersistentClient(
            path=persist_directory,
            settings=Settings(anonymized_telemetry=False)
        )

        # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ë¡œë“œ
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}
        )

        print(f"âœ… ChromaDB initialized at {persist_directory}")
        print(f"ğŸ“Š Collection '{collection_name}' has {self.collection.count()} documents")

    def add_documents(self, chunks: List[Any]) -> None:
        """
        OpenAI embeddingì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ì¶”ê°€ (ê³¼ì œ ë°©ì‹)

        Args:
            chunks: loader.pyì˜ Chunk ë¦¬ìŠ¤íŠ¸
        """
        if not chunks:
            print("âš ï¸  No chunks to add")
            return

        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        texts = [chunk.text for chunk in chunks]

        # OpenAIë¡œ embedding ìƒì„± (ê³¼ì œ ì½”ë“œ ë°©ì‹)
        print(f"ğŸ”„ Generating embeddings for {len(texts)} chunks...")
        response = self.openai_client.embeddings.create(model=self.embed_model, input=texts)
        embeddings = [item.embedding for item in response.data]

        # ChromaDBì— ì¶”ê°€
        ids = [chunk.id for chunk in chunks]
        metadatas = [chunk.metadata for chunk in chunks]

        self.collection.add(
            ids=ids,
            documents=texts,
            embeddings=embeddings,
            metadatas=metadatas
        )

        print(f"âœ… Added {len(chunks)} chunks with OpenAI embeddings")
        print(f"ğŸ“Š Total documents: {self.collection.count()}")

    def search(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """
        ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì§ˆë¬¸
            top_k: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (text, metadata, distance í¬í•¨)
        """
        results = self.collection.query(
            query_texts=[query],
            n_results=top_k
        )

        # ê²°ê³¼ ì •ë¦¬
        formatted_results = []

        if results['ids'] and results['ids'][0]:
            for i in range(len(results['ids'][0])):
                formatted_results.append({
                    "id": results['ids'][0][i],
                    "text": results['documents'][0][i],
                    "metadata": results['metadatas'][0][i] if results['metadatas'] else {},
                    "distance": results['distances'][0][i] if results['distances'] else 0.0
                })

        return formatted_results

    def search_with_openai_embedding(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """
        OpenAI embeddingì„ ì‚¬ìš©í•œ ê²€ìƒ‰ (ê³¼ì œ ë°©ì‹)

        Args:
            query: ê²€ìƒ‰ ì§ˆë¬¸
            top_k: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        # ì§ˆë¬¸ ì„ë² ë”© (ê³¼ì œ ì½”ë“œ ë°©ì‹)
        response = self.openai_client.embeddings.create(model=self.embed_model, input=[query])
        query_embedding = response.data[0].embedding

        # ChromaDB ê²€ìƒ‰
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k
        )

        # ê²°ê³¼ ì •ë¦¬
        formatted_results = []

        if results['ids'] and results['ids'][0]:
            for i in range(len(results['ids'][0])):
                formatted_results.append({
                    "id": results['ids'][0][i],
                    "text": results['documents'][0][i],
                    "metadata": results['metadatas'][0][i] if results['metadatas'] else {},
                    "distance": results['distances'][0][i] if results['distances'] else 0.0
                })

        return formatted_results

    def clear(self) -> None:
        """ì»¬ë ‰ì…˜ ì´ˆê¸°í™”"""
        self.client.delete_collection(self.collection_name)
        self.collection = self.client.create_collection(
            name=self.collection_name,
            metadata={"description": "Movie information chunks"}
        )
        print(f"ğŸ—‘ï¸  Collection '{self.collection_name}' cleared")

    def count(self) -> int:
        """ì €ì¥ëœ ë¬¸ì„œ ê°œìˆ˜"""
        return self.collection.count()


# í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
    store = MovieVectorStore()

    # í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì¶”ê°€
    from ..rag.loader import Chunk

    test_chunks = [
        Chunk(
            id="test_1",
            text="Interstellar is a 2014 science fiction film directed by Christopher Nolan.",
            metadata={"source": "test.txt", "chunk_id": 0}
        ),
        Chunk(
            id="test_2",
            text="The movie explores themes of space travel, time dilation, and human survival.",
            metadata={"source": "test.txt", "chunk_id": 1}
        )
    ]

    # ë¬¸ì„œ ì¶”ê°€
    store.add_documents(test_chunks)

    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    results = store.search("Tell me about Interstellar", top_k=2)

    print("\nğŸ” Search results:")
    for i, result in enumerate(results, 1):
        print(f"\n[{i}] Distance: {result['distance']:.4f}")
        print(f"Text: {result['text'][:100]}...")
        print(f"Metadata: {result['metadata']}")
