"""
vectorstore.py

ChromaDB ê¸°ë°˜ ë²¡í„° ì €ì¥ì†Œ (ê³¼ì œ ë°©ì‹)

"""

import os
from typing import List, Dict, Any
import chromadb
from chromadb.config import Settings
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()


class MovieVectorStore:
    """
    ChromaDB ê¸°ë°˜ ì˜í™” ì •ë³´ ë²¡í„° ì €ì¥ì†Œ (ê³¼ì œ ë°©ì‹)

    ê³¼ì œ ë°©ì‹:
    - OpenAIë¡œ ì§ì ‘ embedding ìƒì„±
    - ChromaDBì— embeddingê³¼ í•¨ê»˜ ì €ì¥
    """

    def __init__(self, persist_directory: str = "data/vector_db", collection_name: str = "movies"):
        """
        ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”

        Args:
            persist_directory: ChromaDB ì €ì¥ ê²½ë¡œ
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
        """
        self.persist_directory = persist_directory
        self.collection_name = collection_name

        # OpenAI client
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.embed_model = os.getenv("EMBED_MODEL", "text-embedding-3-small")

        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ìë™ persist)
        self.client = chromadb.PersistentClient(
            path=persist_directory,
            settings=Settings(anonymized_telemetry=False)
        )

        # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ë¡œë“œ
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}
        )

        print(f"âœ… ChromaDB initialized at {persist_directory}")
        print(f"ğŸ“Š Collection '{collection_name}' has {self.collection.count()} documents")

    def add_documents(self, chunks: List[Any], batch_size: int = 128) -> None:
        if not chunks:
            print("âš ï¸  No chunks to add")
            return

        print(f"ğŸ”„ Generating embeddings for {len(chunks)} chunks in batches of {batch_size}...")

        ids = [chunk.id for chunk in chunks]
        texts = [chunk.text for chunk in chunks]
        metadatas = [chunk.metadata for chunk in chunks]

        total = len(texts)
        for start in range(0, total, batch_size):
            end = min(start + batch_size, total)
            batch_texts = texts[start:end]
            batch_ids = ids[start:end]
            batch_metas = metadatas[start:end]

            resp = self.openai_client.embeddings.create(
                model=self.embed_model,
                input=batch_texts,
            )
            batch_embeddings = [item.embedding for item in resp.data]

            self.collection.add(
                ids=batch_ids,
                documents=batch_texts,
                embeddings=batch_embeddings,
                metadatas=batch_metas,
            )
            print(f"âœ… Added batch {start}-{end-1} (size {end-start})")

        print(f"ğŸ“Š Total documents: {self.collection.count()}")


    def search(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """
        ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì§ˆë¬¸
            top_k: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (text, metadata, distance í¬í•¨)
        """
        results = self.collection.query(
            query_texts=[query],
            n_results=top_k
        )

        # ê²°ê³¼ ì •ë¦¬
        formatted_results = []

        if results['ids'] and results['ids'][0]:
            for i in range(len(results['ids'][0])):
                formatted_results.append({
                    "id": results['ids'][0][i],
                    "text": results['documents'][0][i],
                    "metadata": results['metadatas'][0][i] if results['metadatas'] else {},
                    "distance": results['distances'][0][i] if results['distances'] else 0.0
                })

        return formatted_results

    def search_with_openai_embedding(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """
        OpenAI embeddingì„ ì‚¬ìš©í•œ ê²€ìƒ‰ (ê³¼ì œ ë°©ì‹)

        Args:
            query: ê²€ìƒ‰ ì§ˆë¬¸
            top_k: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        # ì§ˆë¬¸ ì„ë² ë”© (ê³¼ì œ ì½”ë“œ ë°©ì‹)
        response = self.openai_client.embeddings.create(model=self.embed_model, input=[query])
        query_embedding = response.data[0].embedding

        # ChromaDB ê²€ìƒ‰
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k
        )

        # ê²°ê³¼ ì •ë¦¬
        formatted_results = []

        if results['ids'] and results['ids'][0]:
            for i in range(len(results['ids'][0])):
                formatted_results.append({
                    "id": results['ids'][0][i],
                    "text": results['documents'][0][i],
                    "metadata": results['metadatas'][0][i] if results['metadatas'] else {},
                    "distance": results['distances'][0][i] if results['distances'] else 0.0
                })

        return formatted_results

    def clear(self) -> None:
        """ì»¬ë ‰ì…˜ ì´ˆê¸°í™”"""
        self.client.delete_collection(self.collection_name)
        self.collection = self.client.create_collection(
            name=self.collection_name,
            metadata={"description": "Movie information chunks"}
        )
        print(f"ğŸ—‘ï¸  Collection '{self.collection_name}' cleared")

    def count(self) -> int:
        """ì €ì¥ëœ ë¬¸ì„œ ê°œìˆ˜"""
        return self.collection.count()